{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise #2 - Create Fact & Dim Tables\n",
    "\n",
    "Now that the three years of orders are combined into a single dataset, we can begin the processes of transforming the data.\n",
    "\n",
    "In the one record, there are actually four sub-datasets:\n",
    "* The order itself which is the aggregator of the other three datasets.\n",
    "* The line items of each order which includes the price and quantity of each specific item.\n",
    "* The sales rep placing the order.\n",
    "* The customer placing the order - for the sake of simplicity, we will **not** break this dataset out and leave it as part of the order.\n",
    "\n",
    "What we want to do next, is to extract all that data into their respective datasets (except the customer data). \n",
    "\n",
    "In other words, we want to normalize the data, in this case, to reduce data duplication.\n",
    "\n",
    "This exercise is broken up into 5 steps:\n",
    "* Exercise 2.A - Create & Use Database\n",
    "* Exercise 2.B - Load & Cache Batch Orders\n",
    "* Exercise 2.C - Extract Sales Reps\n",
    "* Exercise 2.D - Extract Orders\n",
    "* Exercise 2.E - Extract Line Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_db = \"learning_db\"\n",
    "batch_source_path = \"output/batch_orders_dirty.delta\"\n",
    "orders_table = \"orders\"\n",
    "line_items_table = \"line_items\"\n",
    "sales_reps_table = \"sales_reps\"\n",
    "batch_temp_view = \"batched_orders\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import get_spark_session\n",
    "\n",
    "spark = get_spark_session()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> Exercise #2.A - Create &amp; Use Database</h2>\n",
    "\n",
    "**In this step you will need to:**\n",
    "* Create the database identified by the variable **`user_db`**\n",
    "* Use the database identified by the variable **`user_db`** so that any tables created in this notebook are **NOT** added to the **`default`** database\n",
    "\n",
    "**Special Notes**\n",
    "* Do not hard-code the database name - in some scenarios this will result in validation errors.\n",
    "* For assistence with the SQL command to create a database, see <a href=\"https://docs.databricks.com/spark/latest/spark-sql/language-manual/sql-ref-syntax-ddl-create-database.html\" target=\"_blank\">CREATE DATABASE</a> on the Databricks docs website.\n",
    "* For assistence with the SQL command to use a database, see <a href=\"https://docs.databricks.com/spark/latest/spark-sql/language-manual/sql-ref-syntax-ddl-usedb.html\" target=\"_blank\">USE DATABASE</a> on the Databricks docs website."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Exercise #3.A\n",
    "\n",
    "Implement your solution in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Use this cell to complete your solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> Exercise #2.B - Load &amp; Cache Batch Orders</h2>\n",
    "\n",
    "Next, we need to load the batch orders from the previous exercise and then cache them in preparation to transform the data later in this exercise.\n",
    "\n",
    "**In this step you will need to:**\n",
    "* Load the delta dataset we created in the previous exercise, identified by the variable **`batch_source_path`**.\n",
    "* Using that same dataset, create a temporary view identified by the variable **`batch_temp_view`**.\n",
    "* Cache the temporary view."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Exercise #3.B\n",
    "\n",
    "Implement your solution in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Use this cell to complete your solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> Exercise #2.C - Extract Sales Reps</h2>\n",
    "\n",
    "Our batched orders from Exercise #1 contains thousands of orders and with every order, is the name, SSN, address and other information on the sales rep making the order.\n",
    "\n",
    "We can use this data to create a table of just our sales reps.\n",
    "\n",
    "If you consider that we have only ~100 sales reps, but thousands of orders, we are going to have a lot of duplicate data in this space.\n",
    "\n",
    "Also unique to this set of data, is the fact that social security numbers were not always sanitized meaning sometime they were formatted with hyphens and in other cases they were not - this is something we will have to address here.\n",
    "\n",
    "**In this step you will need to:**\n",
    "* Load the table **`batched_orders`** (identified by the variable **`batch_temp_view`**)\n",
    "* The SSN numbers have errors in them that we want to track - add the **`boolean`** column **`_error_ssn_format`** - for any case where **`sales_rep_ssn`** has a hypen in it, set this value to **`true`** otherwise **`false`**\n",
    "* Convert various columns from their string representation to the specified type:\n",
    "  * The column **`sales_rep_ssn`** should be represented as a **`Long`** (Note: You will have to first clean the column by removing extreneous hyphens in some records)\n",
    "  * The column **`sales_rep_zip`** should be represented as an **`Integer`**\n",
    "* Remove the columns not directly related to the sales-rep record:\n",
    "  * Unrelated ID columns: **`submitted_at`**, **`order_id`**, **`customer_id`**\n",
    "  * Shipping address columns: **`shipping_address_attention`**, **`shipping_address_address`**, **`shipping_address_city`**, **`shipping_address_state`**, **`shipping_address_zip`**\n",
    "  * Product columns: **`product_id`**, **`product_quantity`**, **`product_sold_price`**\n",
    "* Because there is one record per product ordered (many products per order), not to mention one sales rep placing many orders (many orders per sales rep), there will be duplicate records for our sales reps. Remove all duplicate records, making sure to exclude **`ingest_file_name`** and **`ingested_at`** from the evaluation of duplicate records\n",
    "* Load the dataset to the managed delta table **`sales_rep_scd`** (identified by the variable **`sales_reps_table`**)\n",
    "\n",
    "**Additional Requirements:**<br/>\n",
    "The schema for the **`sales_rep_scd`** table must be:\n",
    "* **`sales_rep_id`**:**`string`**\n",
    "* **`sales_rep_ssn`**:**`long`**\n",
    "* **`sales_rep_first_name`**:**`string`**\n",
    "* **`sales_rep_last_name`**:**`string`**\n",
    "* **`sales_rep_address`**:**`string`**\n",
    "* **`sales_rep_city`**:**`string`**\n",
    "* **`sales_rep_state`**:**`string`**\n",
    "* **`sales_rep_zip`**:**`integer`**\n",
    "* **`ingest_file_name`**:**`string`**\n",
    "* **`ingested_at`**:**`timestamp`**\n",
    "* **`_error_ssn_format`**:**`boolean`**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Exercise #2.C\n",
    "\n",
    "Implement your solution in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Use this cell to complete your solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> Exercise #2.D - Extract Orders</h2>\n",
    "\n",
    "Our batched orders from Exercise 01 contains one line per product meaning there are multiple records per order.\n",
    "\n",
    "The goal of this step is to extract just the order details (excluding the sales rep and line items)\n",
    "\n",
    "**In this step you will need to:**\n",
    "* Load the table **`batched_orders`** (identified by the variable **`batch_temp_view`**)\n",
    "* Convert various columns from their string representation to the specified type:\n",
    "  * The column **`submitted_at`** is a \"unix epoch\" (number of seconds since 1970-01-01 00:00:00 UTC) and should be represented as a **`Timestamp`**\n",
    "  * The column **`shipping_address_zip`** should be represented as an **`Integer`**\n",
    "* Remove the columns not directly related to the order record:\n",
    "  * Sales reps columns: **`sales_rep_ssn`**, **`sales_rep_first_name`**, **`sales_rep_last_name`**, **`sales_rep_address`**, **`sales_rep_city`**, **`sales_rep_state`**, **`sales_rep_zip`**\n",
    "  * Product columns: **`product_id`**, **`product_quantity`**, **`product_sold_price`**\n",
    "* Because there is one record per product ordered (many products per order), there will be duplicate records for each order. Remove all duplicate records, making sure to exclude **`ingest_file_name`** and **`ingested_at`** from the evaluation of duplicate records\n",
    "* Add the column **`submitted_yyyy_mm`** which is a **`string`** derived from **`submitted_at`** and is formatted as \"**yyyy-MM**\".\n",
    "* Load the dataset to the managed delta table **`orders`** (identified by the variable **`orders_table`**)\n",
    "  * In thise case, the data must also be partitioned by **`submitted_yyyy_mm`**\n",
    "\n",
    "**Additional Requirements:**\n",
    "* The schema for the **`orders`** table must be:\n",
    "  * **`submitted_at:timestamp`**\n",
    "  * **`submitted_yyyy_mm`** using the format \"**yyyy-MM**\"\n",
    "  * **`order_id:string`**\n",
    "  * **`customer_id:string`**\n",
    "  * **`sales_rep_id:string`**\n",
    "  * **`shipping_address_attention:string`**\n",
    "  * **`shipping_address_address:string`**\n",
    "  * **`shipping_address_city:string`**\n",
    "  * **`shipping_address_state:string`**\n",
    "  * **`shipping_address_zip:integer`**\n",
    "  * **`ingest_file_name:string`**\n",
    "  * **`ingested_at:timestamp`**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Exercise #2.D\n",
    "\n",
    "Implement your solution in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Use this cell to complete your solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> Exercise #2.E - Extract Line Items</h2>\n",
    "\n",
    "Now that we have extracted sales reps and orders, we next want to extract the specific line items of each order.\n",
    "\n",
    "**In this step you will need to:**\n",
    "* Load the table **`batched_orders`** (identified by the variable **`batch_temp_view`**)\n",
    "* Retain the following columns (see schema below)\n",
    "  * The correlating ID columns: **`order_id`** and **`product_id`**\n",
    "  * The two product-specific columns: **`product_quantity`** and **`product_sold_price`**\n",
    "  * The two ingest columns: **`ingest_file_name`** and **`ingested_at`**\n",
    "* Convert various columns from their string representation to the specified type:\n",
    "  * The column **`product_quantity`** should be represented as an **`Integer`**\n",
    "  * The column **`product_sold_price`** should be represented as an **`Decimal`** with two decimal places as in **`decimal(10,2)`**\n",
    "* Load the dataset to the managed delta table **`line_items`** (identified by the variable **`line_items_table`**)\n",
    "\n",
    "**Additional Requirements:**\n",
    "* The schema for the **`line_items`** table must be:\n",
    "  * **`order_id`**:**`string`**\n",
    "  * **`product_id`**:**`string`**\n",
    "  * **`product_quantity`**:**`integer`**\n",
    "  * **`product_sold_price`**:**`decimal(10,2)`**\n",
    "  * **`ingest_file_name`**:**`string`**\n",
    "  * **`ingested_at`**:**`timestamp`**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Exercise #2.E\n",
    "\n",
    "Implement your solution in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Use this cell to complete your solution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9ead50db5f464cadce5ba018366328249412102842550c0c50bef2a2fd10d90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
